{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Q1.\n",
    "\n",
    "Add methods `__iter__` to your project Time Series class to iterate over values, a method `itertimes` to iterate over times, a method `itervalues` to iterate over values, and a method `iteritems` to iterate over time-value pairs. (This is a similar interface to python dictionaries). To test these, check both the types of the results and the answers you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "import numpy as np\n",
    "from lazy import *\n",
    "\n",
    "class TimeSeries():\n",
    "    '''\n",
    "    \"\"\"\n",
    "Help on package TimeSeries:\n",
    "\n",
    "NAME\n",
    "    TimeSeries\n",
    "\n",
    "DESCRIPTION\n",
    "    TimeSeries\n",
    "    =====\n",
    "    \n",
    "    Provides\n",
    "      1. An sequence or any iterable objects\n",
    "    \n",
    "    How to use the documentation\n",
    "    ----------------------------\n",
    "    Documentation is available in two forms: docstrings provided\n",
    "    with the code, and a loose standing reference guide, available from\n",
    "    `the TimeSeries homepage <https://github.com/cs207-project>`_.\n",
    "    \n",
    "    We recommend exploring the docstrings using\n",
    "    `IPython <http://ipython.scipy.org>`_, an advanced Python shell with\n",
    "    TAB-completion and introspection capabilities.  See below for further\n",
    "    instructions.\n",
    "    \n",
    "    The docstring examples assume that `numpy` has been imported as `np`::  \n",
    "      \n",
    "    \n",
    "    \n",
    "     |  Methods inherited from builtins.RuntimeWarning:\n",
    "     |  \n",
    "     |  __init__(self, *args, **kwargs)\n",
    "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
    "     |      Stors a TimeSeries in self.TimeSeries_\n",
    "     |    \n",
    "     |  __repr__(self, /)\n",
    "     |      Return a printable sequence shown in python list format containing all values in [self].\n",
    "     |  \n",
    "     |  __str__(self, /)\n",
    "     |      Return a printable abbreviated sequence of maximum first 100 entrees.\n",
    "     |  \n",
    "     |  __getitem__(self, index)\n",
    "     |      Return self[index]\n",
    "     |\n",
    "     |  __setitem__(self, index, values)\n",
    "     |      Set self[index] = values\n",
    "     |\n",
    "     |  __len__(self)\n",
    "     |      Return len(self.TimeSeries_)\n",
    "     Examples\n",
    "     --------\n",
    "     >>> a = TimeSeries(np.arange(0,100))\n",
    "     >>> len(a)\n",
    "     100\n",
    "     >>> a[2]\n",
    "     2\n",
    "     >>> a[2]=3\n",
    "     >>> a[2]\n",
    "     3\n",
    "    '''\n",
    "    def __init__(self, times, values):\n",
    "        if (iter(times) and iter(values)):\n",
    "            # reorder according to Time step\n",
    "            idx = np.argsort(times)\n",
    "            times = np.array(times)[idx]\n",
    "            values = np.array(values)[idx]\n",
    "\n",
    "            self._TimeSeries=np.vstack((times,values))\n",
    "            self._vindex = 0\n",
    "            self._values = self._TimeSeries[1]\n",
    "            self._times = self._TimeSeries[0]\n",
    "    \n",
    "    @property\n",
    "    @lazy\n",
    "    def lazy(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._TimeSeries[0])\n",
    "    \n",
    "    def __contains__(self, time):\n",
    "        index = np.where(self._TimeSeries[0]==time)\n",
    "        return index[0].size>0\n",
    "            \n",
    "    \n",
    "    def __getitem__(self,time):\n",
    "        if (time in self):\n",
    "            index = np.where(self._TimeSeries[0]==time)\n",
    "            return self._TimeSeries[1][index]\n",
    "        else:\n",
    "            print (\"no time point at t={0}\".format(time))\n",
    "\n",
    "    def __setitem__(self,time,value):\n",
    "        if (time in self):\n",
    "            index = np.where(self._TimeSeries[0]==time)\n",
    "            self._TimeSeries[1][index]=value\n",
    "        else:\n",
    "            print (\"no time point at t={0}\".format(time))\n",
    "            \n",
    "    def __iter__(self):\n",
    "#         return iter(self._TimeSeries[1])\n",
    "        for v in self._values:#note this is implicitly making an iter from the list\n",
    "            yield v\n",
    "    \n",
    "    def itertimes(self):\n",
    "        it = iter(self._times)\n",
    "        while True:\n",
    "            try:\n",
    "                nextval = next(it)\n",
    "                print(nextval)\n",
    "            except StopIteration:\n",
    "                del it\n",
    "                break\n",
    "    \n",
    "    def itervalues(self):\n",
    "        it = iter(self.values)\n",
    "        while True:\n",
    "            try:\n",
    "                nextval = next(it)\n",
    "                print(nextval)\n",
    "            except StopIteration:\n",
    "                del it\n",
    "                break\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"%r\"%(self._TimeSeries)\n",
    "    \n",
    "    def __str__(self):\n",
    "        className = type(self).__name__\n",
    "        if len(self._TimeSeries)>100:\n",
    "            return \"%s\" %('['+(str(self._TimeSeries[:99]))[1:-1]+'...'+']')\n",
    "        else:\n",
    "            return \"%s\" %(self._TimeSeries)\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return np.array_equal(self._TimeSeries, other._TimeSeries)\n",
    "        \n",
    "    def values(self):\n",
    "        return self._values\n",
    "    \n",
    "    def times(self):\n",
    "        return self._times\n",
    "    \n",
    "    def mean(self):        \n",
    "        if(len(self._values) == 0):\n",
    "            raise ValueError(\"cant calculate mean of length 0 list\")\n",
    "        return np.mean(self._values)\n",
    "    \n",
    "    def median(self):\n",
    "        if(len(self._values) == 0):\n",
    "            raise ValueError(\"cant calculate median of length 0 list\")\n",
    "        return np.median(self._values)\n",
    "    \n",
    "    def interpolate(self, times):\n",
    "        new_values = []\n",
    "        for time in times:\n",
    "            if time > self._times[-1]: # over the rightest boundary\n",
    "                new_values.append(self._values[-1])\n",
    "            elif time < self._times[0]: # over the leftest boundary\n",
    "                new_values.append(self._values[0])\n",
    "            elif time in self._times:\n",
    "                new_values.append(self.__getitem__(time))\n",
    "            else : #within boundary\n",
    "                for i in range(len(self._times)):\n",
    "                    if self._times[i] > time:\n",
    "                        left_value = self._values[i-1]\n",
    "                        right_value = self._values[i]\n",
    "                        left_time = self._times[i-1]\n",
    "                        right_time = self._times[i]\n",
    "                        #interpolate\n",
    "                        new_values.append(left_value + (right_value - left_value)/(right_time - left_time)*(time - left_time))\n",
    "                        break\n",
    "        return TimeSeries(times, new_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = TimeSeries([1,2],[2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "a.itertimes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.\n",
    "\n",
    "An online mean and standard deviation algorithm.\n",
    "\n",
    "Below is a function to generate a potentially infinite stream of 1-D data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import normalvariate, random\n",
    "from itertools import count\n",
    "def make_data(m, stop=None):\n",
    "    for _ in count():\n",
    "        if stop and _ > stop:\n",
    "            break\n",
    "        yield 1.0e09 + normalvariate(0, m*random() )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an implementation of an online mean algorithm..see http://www.johndcook.com/blog/standard_deviation/ and the link to http://www.johndcook.com/blog/2008/09/26/comparing-three-methods-of-computing-standard-deviation/ in-between. (Convince yourselves of the formulas...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def online_mean(iterator):\n",
    "    n = 0\n",
    "    mu = 0\n",
    "    for value in iterator:\n",
    "        n += 1\n",
    "        delta = value - mu\n",
    "        mu = mu + delta/n\n",
    "        yield mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use out generator functions to implement iterators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[999999998.2582062,\n",
       " 1000000000.4736316,\n",
       " 999999998.5142187,\n",
       " 999999999.3139703,\n",
       " 999999999.8882793,\n",
       " 999999996.7541624,\n",
       " 1000000000.6411918,\n",
       " 1000000000.7138886,\n",
       " 999999999.6304762,\n",
       " 999999996.9589375,\n",
       " 1000000007.2603697]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = make_data(5, 10)\n",
    "list(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1000000000.2870655,\n",
       " 1000000001.176422,\n",
       " 1000000000.042941,\n",
       " 1000000000.2380912,\n",
       " 999999999.7261815,\n",
       " 999999998.9765905,\n",
       " 999999999.1346492,\n",
       " 999999998.3961082,\n",
       " 999999998.0929016,\n",
       " 999999998.2746978,\n",
       " 999999997.9391755,\n",
       " 999999997.8113656,\n",
       " 999999997.7950065,\n",
       " 999999997.9758118,\n",
       " 999999998.172254,\n",
       " 999999998.3052565,\n",
       " 999999998.4001087,\n",
       " 999999998.6617073,\n",
       " 999999998.6800115,\n",
       " 999999998.7713877,\n",
       " 999999998.8348559,\n",
       " 999999998.8681365,\n",
       " 999999999.0713048,\n",
       " 999999999.2128855,\n",
       " 999999999.2259862,\n",
       " 999999999.2090044,\n",
       " 999999999.1819044,\n",
       " 999999999.2085285,\n",
       " 999999999.2478731,\n",
       " 999999999.3256087,\n",
       " 999999999.3399253,\n",
       " 999999999.3892065,\n",
       " 999999999.3683349,\n",
       " 999999999.3727993,\n",
       " 999999999.35683,\n",
       " 999999999.2953542,\n",
       " 999999999.1424577,\n",
       " 999999999.1731287,\n",
       " 999999999.2291478,\n",
       " 999999999.249976,\n",
       " 999999999.193216,\n",
       " 999999999.2735772,\n",
       " 999999999.4324152,\n",
       " 999999999.4907136,\n",
       " 999999999.5150396,\n",
       " 999999999.5278269,\n",
       " 999999999.3776834,\n",
       " 999999999.4161061,\n",
       " 999999999.4253076,\n",
       " 999999999.3328378,\n",
       " 999999999.4432294,\n",
       " 999999999.4323082,\n",
       " 999999999.4746253,\n",
       " 999999999.4935265,\n",
       " 999999999.5074441,\n",
       " 999999999.410972,\n",
       " 999999999.3425199,\n",
       " 999999999.3892039,\n",
       " 999999999.3847342,\n",
       " 999999999.5459751,\n",
       " 999999999.55355,\n",
       " 999999999.5717441,\n",
       " 999999999.5715795,\n",
       " 999999999.5602624,\n",
       " 999999999.5597719,\n",
       " 999999999.5379815,\n",
       " 999999999.4971929,\n",
       " 999999999.5636637,\n",
       " 999999999.5960386,\n",
       " 999999999.6060842,\n",
       " 999999999.5915012,\n",
       " 999999999.5800847,\n",
       " 999999999.5585253,\n",
       " 999999999.5322658,\n",
       " 999999999.6326436,\n",
       " 999999999.6630949,\n",
       " 999999999.6552471,\n",
       " 999999999.6381091,\n",
       " 999999999.620333,\n",
       " 999999999.6272517,\n",
       " 999999999.5822917,\n",
       " 999999999.562781,\n",
       " 999999999.5636909,\n",
       " 999999999.5673333,\n",
       " 999999999.6098477,\n",
       " 999999999.6095045,\n",
       " 999999999.6857638,\n",
       " 999999999.7041926,\n",
       " 999999999.7076869,\n",
       " 999999999.7568551,\n",
       " 999999999.7589866,\n",
       " 999999999.7688638,\n",
       " 999999999.7090906,\n",
       " 999999999.7162153,\n",
       " 999999999.7765393,\n",
       " 999999999.7643311,\n",
       " 999999999.7686739,\n",
       " 999999999.7690679,\n",
       " 999999999.7892096,\n",
       " 999999999.8161688,\n",
       " 999999999.8371903]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = online_mean(make_data(5, 100))\n",
    "print(type(g))\n",
    "list(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1\n",
    "\n",
    "Implement the standard deviation algorithm as a generator function as\n",
    "\n",
    "```python\n",
    "def online_mean_dev(iterator):\n",
    "    BLA BLA\n",
    "    if n > 1:\n",
    "        stddev = math.sqrt(dev_accum/(n-1))\n",
    "        yield (n, value, mu, stddev)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "Sk = Sk-1 + (xk – Mk-1)*(xk – Mk)\n",
    "m_newS = m_oldS + (x - m_oldM)*(x - m_newM);\n",
    "    \n",
    "                // set up for next iteration\n",
    "                m_oldM = m_newM; \n",
    "                m_oldS = m_newS;\n",
    "                \n",
    "                \n",
    "def online_mean_dev(iterator):\n",
    "    if n == 1:\n",
    "        yield \n",
    "    if n > 1:\n",
    "        stddev = math.sqrt(dev_accum/(n-1))\n",
    "        yield (n, value, mu, stddev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we make 100000 element data, and run this iterator on it (imagine running this on a time-series being slowly read from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_stats = online_mean_dev(make_data(5, 100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3.\n",
    "\n",
    "Let's do Anomaly detection. Write a routine `is_ok`:\n",
    "\n",
    "```python\n",
    "def is_ok(level, t)\n",
    "```\n",
    "\n",
    "which takes a tuple like the one yielded by your code above and returns True if the value is inbetween `level`-$\\sigma$ of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this function to create a predicate passed through to `itertools.filterfalse` which is then used to obtain an iterator on the anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import filterfalse\n",
    "pred = lambda t: is_ok(5, t)\n",
    "anomalies = filterfalse(pred, data_with_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We materialize the anomalies..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(anomalies)#materialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To think of, but not hand in\n",
    "\n",
    "What kinds of anomalies will this algorithm pick up? What kinds would a shorter \"window\" of anomaly detection, like 100 points around the time in question pick? How might you create an algorithm which does window based averaging? (hint: the window size is small compared to the time series size). \n",
    "\n",
    "Finally think a bit of how you might implement all of this in a production environment..remember that data streaming in might get backed up when you handle an anomaly.\n",
    "\n",
    "(Some inspiration might accrue if you look at the docs for `collections.deque`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
