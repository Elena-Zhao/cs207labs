{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Q1.\n",
    "\n",
    "Add methods `__iter__` to your project Time Series class to iterate over values, a method `itertimes` to iterate over times, a method `itervalues` to iterate over values, and a method `iteritems` to iterate over time-value pairs. (This is a similar interface to python dictionaries). To test these, check both the types of the results and the answers you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "import numpy as np\n",
    "from lazy import *\n",
    "\n",
    "class TimeSeries():\n",
    "    '''\n",
    "    \"\"\"\n",
    "Help on package TimeSeries:\n",
    "\n",
    "NAME\n",
    "    TimeSeries\n",
    "\n",
    "DESCRIPTION\n",
    "    TimeSeries\n",
    "    =====\n",
    "    \n",
    "    Provides\n",
    "      1. An sequence or any iterable objects\n",
    "    \n",
    "    How to use the documentation\n",
    "    ----------------------------\n",
    "    Documentation is available in two forms: docstrings provided\n",
    "    with the code, and a loose standing reference guide, available from\n",
    "    `the TimeSeries homepage <https://github.com/cs207-project>`_.\n",
    "    \n",
    "    We recommend exploring the docstrings using\n",
    "    `IPython <http://ipython.scipy.org>`_, an advanced Python shell with\n",
    "    TAB-completion and introspection capabilities.  See below for further\n",
    "    instructions.\n",
    "    \n",
    "    The docstring examples assume that `numpy` has been imported as `np`::  \n",
    "      \n",
    "    \n",
    "    \n",
    "     |  Methods inherited from builtins.RuntimeWarning:\n",
    "     |  \n",
    "     |  __init__(self, *args, **kwargs)\n",
    "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
    "     |      Stors a TimeSeries in self.TimeSeries_\n",
    "     |    \n",
    "     |  __repr__(self, /)\n",
    "     |      Return a printable sequence shown in python list format containing all values in [self].\n",
    "     |  \n",
    "     |  __str__(self, /)\n",
    "     |      Return a printable abbreviated sequence of maximum first 100 entrees.\n",
    "     |  \n",
    "     |  __getitem__(self, index)\n",
    "     |      Return self[index]\n",
    "     |\n",
    "     |  __setitem__(self, index, values)\n",
    "     |      Set self[index] = values\n",
    "     |\n",
    "     |  __len__(self)\n",
    "     |      Return len(self.TimeSeries_)\n",
    "     Examples\n",
    "     --------\n",
    "     >>> a = TimeSeries(np.arange(0,100))\n",
    "     >>> len(a)\n",
    "     100\n",
    "     >>> a[2]\n",
    "     2\n",
    "     >>> a[2]=3\n",
    "     >>> a[2]\n",
    "     3\n",
    "    '''\n",
    "    def __init__(self, times, values):\n",
    "        if (iter(times) and iter(values)):\n",
    "            # reorder according to Time step\n",
    "            idx = np.argsort(times)\n",
    "            times = np.array(times)[idx]\n",
    "            values = np.array(values)[idx]\n",
    "\n",
    "            self._TimeSeries=np.vstack((times,values))\n",
    "            self._vindex = 0\n",
    "            self._values = self._TimeSeries[1]\n",
    "            self._times = self._TimeSeries[0]\n",
    "    \n",
    "    @property\n",
    "    @lazy\n",
    "    def lazy(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._TimeSeries[0])\n",
    "    \n",
    "    def __contains__(self, time):\n",
    "        index = np.where(self._TimeSeries[0]==time)\n",
    "        return index[0].size>0\n",
    "            \n",
    "    \n",
    "    def __getitem__(self,time):\n",
    "        if (time in self):\n",
    "            index = np.where(self._TimeSeries[0]==time)\n",
    "            return self._TimeSeries[1][index]\n",
    "        else:\n",
    "            print (\"no time point at t={0}\".format(time))\n",
    "\n",
    "    def __setitem__(self,time,value):\n",
    "        if (time in self):\n",
    "            index = np.where(self._TimeSeries[0]==time)\n",
    "            self._TimeSeries[1][index]=value\n",
    "        else:\n",
    "            print (\"no time point at t={0}\".format(time))\n",
    "            \n",
    "    def __iter__(self):\n",
    "#         return iter(self._TimeSeries[1])\n",
    "        for v in self._values:#note this is implicitly making an iter from the list\n",
    "            yield v\n",
    "    \n",
    "    def itertimes(self):\n",
    "        it = iter(self._times)\n",
    "        while True:\n",
    "            try:\n",
    "                nextval = next(it)\n",
    "                print(nextval)\n",
    "            except StopIteration:\n",
    "                del it\n",
    "                break\n",
    "    \n",
    "    def itervalues(self):\n",
    "        it = iter(self._times)\n",
    "        while True:\n",
    "            try:\n",
    "                nextval = next(it)\n",
    "                print(nextval)\n",
    "            except StopIteration:\n",
    "                del it\n",
    "                break\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"%r\"%(self._TimeSeries)\n",
    "    \n",
    "    def __str__(self):\n",
    "        className = type(self).__name__\n",
    "        if len(self._TimeSeries)>100:\n",
    "            return \"%s\" %('['+(str(self._TimeSeries[:99]))[1:-1]+'...'+']')\n",
    "        else:\n",
    "            return \"%s\" %(self._TimeSeries)\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return np.array_equal(self._TimeSeries, other._TimeSeries)\n",
    "        \n",
    "    def values(self):\n",
    "        return self._values\n",
    "    \n",
    "    def times(self):\n",
    "        return self._times\n",
    "    \n",
    "    def mean(self):        \n",
    "        if(len(self._values) == 0):\n",
    "            raise ValueError(\"cant calculate mean of length 0 list\")\n",
    "        return np.mean(self._values)\n",
    "    \n",
    "    def median(self):\n",
    "        if(len(self._values) == 0):\n",
    "            raise ValueError(\"cant calculate median of length 0 list\")\n",
    "        return np.median(self._values)\n",
    "    \n",
    "    def interpolate(self, times):\n",
    "        new_values = []\n",
    "        for time in times:\n",
    "            if time > self._times[-1]: # over the rightest boundary\n",
    "                new_values.append(self._values[-1])\n",
    "            elif time < self._times[0]: # over the leftest boundary\n",
    "                new_values.append(self._values[0])\n",
    "            elif time in self._times:\n",
    "                new_values.append(self.__getitem__(time))\n",
    "            else : #within boundary\n",
    "                for i in range(len(self._times)):\n",
    "                    if self._times[i] > time:\n",
    "                        left_value = self._values[i-1]\n",
    "                        right_value = self._values[i]\n",
    "                        left_time = self._times[i-1]\n",
    "                        right_time = self._times[i]\n",
    "                        #interpolate\n",
    "                        new_values.append(left_value + (right_value - left_value)/(right_time - left_time)*(time - left_time))\n",
    "                        break\n",
    "        return TimeSeries(times, new_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = TimeSeries([1,2],[2,3])\n",
    "next(a.itertimes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.\n",
    "\n",
    "An online mean and standard deviation algorithm.\n",
    "\n",
    "Below is a function to generate a potentially infinite stream of 1-D data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import normalvariate, random\n",
    "from itertools import count\n",
    "def make_data(m, stop=None):\n",
    "    for _ in count():\n",
    "        if stop and _ > stop:\n",
    "            break\n",
    "        yield 1.0e09 + normalvariate(0, m*random() )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an implementation of an online mean algorithm..see http://www.johndcook.com/blog/standard_deviation/ and the link to http://www.johndcook.com/blog/2008/09/26/comparing-three-methods-of-computing-standard-deviation/ in-between. (Convince yourselves of the formulas...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def online_mean(iterator):\n",
    "    n = 0\n",
    "    mu = 0\n",
    "    for value in iterator:\n",
    "        n += 1\n",
    "        delta = value - mu\n",
    "        mu = mu + delta/n\n",
    "        yield mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use out generator functions to implement iterators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = make_data(5, 10)\n",
    "list(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = online_mean(make_data(5, 100))\n",
    "print(type(g))\n",
    "list(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1\n",
    "\n",
    "Implement the standard deviation algorithm as a generator function as\n",
    "\n",
    "```python\n",
    "def online_mean_dev(iterator):\n",
    "    BLA BLA\n",
    "    if n > 1:\n",
    "        stddev = math.sqrt(dev_accum/(n-1))\n",
    "        yield (n, value, mu, stddev)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we make 100000 element data, and run this iterator on it (imagine running this on a time-series being slowly read from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_stats = online_mean_dev(make_data(5, 100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3.\n",
    "\n",
    "Let's do Anomaly detection. Write a routine `is_ok`:\n",
    "\n",
    "```python\n",
    "def is_ok(level, t)\n",
    "```\n",
    "\n",
    "which takes a tuple like the one yielded by your code above and returns True if the value is inbetween `level`-$\\sigma$ of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this function to create a predicate passed through to `itertools.filterfalse` which is then used to obtain an iterator on the anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import filterfalse\n",
    "pred = lambda t: is_ok(5, t)\n",
    "anomalies = filterfalse(pred, data_with_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We materialize the anomalies..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(anomalies)#materialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To think of, but not hand in\n",
    "\n",
    "What kinds of anomalies will this algorithm pick up? What kinds would a shorter \"window\" of anomaly detection, like 100 points around the time in question pick? How might you create an algorithm which does window based averaging? (hint: the window size is small compared to the time series size). \n",
    "\n",
    "Finally think a bit of how you might implement all of this in a production environment..remember that data streaming in might get backed up when you handle an anomaly.\n",
    "\n",
    "(Some inspiration might accrue if you look at the docs for `collections.deque`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
